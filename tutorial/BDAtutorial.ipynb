{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This Jupyter Notebook is about Bayesian Data Analysis for neuroscience data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is part of a 20-week internship project carried out at Ulster University.\n",
    "The main goal of the project is to make advanced Bayesian statistical models more accessible\n",
    "to experimental neuroscientists through user-friendly code, tutorials, and examples.\n",
    "\n",
    "Specifically, this notebook focuses on applying existing Bayesian models to neuroscience datasets\n",
    "using libraries in Python.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Apply the existing Bayesian models to a neuroscience dataset from scratch,\n",
    "   documenting each step as if it were for a beginner user.\n",
    "\n",
    "2. Design a simple and reproducible analysis pipeline using PyMC.\n",
    "\n",
    "3. Produce clear, well-documented code that can later be integrated into\n",
    "   an interactive tutorial or a web application.\n",
    "\n",
    "## Author\n",
    "\n",
    "- Mathis DA SILVA\n",
    "- Ulster University Internship (July–December 2025)\n",
    "- Supervisors: Dr. Cian O'Donnell & Dr. Conor Houghton\n",
    "\n",
    "## References\n",
    "\n",
    "- [Dataset from \"Classification of psychedelics and psychoactive drugs based on brain-wide imaging of cellular c-Fos expression\"](https://www.nature.com/articles/s41467-025-56850-6#Sec25)\n",
    "- [Hierarchical Bayesian modeling of multi-region brain cell count data](https://elifesciences.org/reviewed-preprints/102391v1)\n",
    "- [Statistical Rethinking 2023 PDF](https://civil.colorado.edu/~balajir/CVEN6833/bayes-resources/RM-StatRethink-Bayes.pdf)\n",
    "- [Statistical Rethinking 2023 Videos](https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus)"
   ],
   "id": "114234684bc0bff3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we call libraries that we will use in this notebook for the moment.",
   "id": "f766ed37ffa3c487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import seaborn as sns"
   ],
   "id": "da900d7b8f041b53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will use the dataset from the paper \"Classification of psychedelics and psychoactive drugs based on brain-wide imaging of cellular c-Fos expression\".\n",
    "\n"
   ],
   "id": "7a86c1e83777a26a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = pd.read_excel('data/dataset_neuroscience_vo.xlsx')\n",
    "\n",
    "dataset"
   ],
   "id": "df2778247f09bc9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Indications:\n",
    "\n",
    "Previously, we added the dataset. In which, the first three columns represent brain regions with name and abbreviation. Others represent mice group by drugs as **MDMA**, **Ketamine**, **Fluoxetine**, ...\n",
    "\n",
    "There are **64 mice** in total, and each mouse has a value for each brain region. The values represent the number of cells expressing c-Fos, a marker of **neuronal activity**. Plus, there are **315 brain regions** in the dataset."
   ],
   "id": "65a886dbf28b555f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Statistical Models\n",
    "---\n",
    "\n",
    "We will use a **Hierarchical Bayesian Model** to analyze the dataset. The model will allow us to account for the hierarchical structure of the data, where measurements are nested within brain regions and mice. Models are: **Poisson**, **Horseshoe** and **Zero-Inflated Poisson (ZIP)**.\n",
    "\n",
    "For the moment, we will use a part of the dataset, specifically the first 20 brain regions and 2 groups of mice."
   ],
   "id": "77b5f210b8462e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset1 = pd.read_excel('data/dataset_neuroscience_1.xlsx')\n",
    "\n",
    "dataset1"
   ],
   "id": "c0d440660cd1100f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will prepare the data for the model.",
   "id": "4f0d33ee7c499a33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_data(dataset):\n",
    "    \"\"\"Prépare les données pour l'analyse PyMC\"\"\"\n",
    "    # Supprimer la dernière ligne qui contient les informations de sexe\n",
    "    data_clean = dataset.iloc[:-1].copy()\n",
    "\n",
    "    # Séparer les métadonnées des données de comptage\n",
    "    metadata = data_clean[['abbreviation', 'region name', 'brain area']]\n",
    "    count_data = data_clean.iloc[:, 3:]  # Toutes les colonnes de comptage\n",
    "\n",
    "    # Convertir en format long pour l'analyse\n",
    "    count_data_long = []\n",
    "    region_indices = []\n",
    "    group_indices = []\n",
    "\n",
    "    for region_idx, region in enumerate(metadata['abbreviation']):\n",
    "        for col_idx, column in enumerate(count_data.columns):\n",
    "            group = column.split(' ')[0]  # Extraire le nom du groupe (A-SSRI, C-SSRI)\n",
    "            count = count_data.iloc[region_idx, col_idx]\n",
    "\n",
    "            count_data_long.append(count)\n",
    "            region_indices.append(region_idx)\n",
    "            group_indices.append(0 if 'A-SSRI' in column else 1)  # A-SSRI=0, C-SSRI=1\n",
    "\n",
    "    return {\n",
    "        'counts': np.array(count_data_long, dtype=int),\n",
    "        'region_idx': np.array(region_indices),\n",
    "        'group_idx': np.array(group_indices),\n",
    "        'n_regions': len(metadata),\n",
    "        'n_groups': 2,\n",
    "        'region_names': metadata['abbreviation'].tolist(),\n",
    "        'group_names': ['A-SSRI', 'C-SSRI']\n",
    "    }\n",
    "\n",
    "# Préparer les données\n",
    "data = prepare_data(dataset1)\n",
    "print(f\"Nombre de régions: {data['n_regions']}\")\n",
    "print(f\"Nombre de groupes: {data['n_groups']}\")\n",
    "print(f\"Nombre total d'observations: {len(data['counts'])}\")\n",
    "print(f\"Régions: {data['region_names'][:5]}...\")"
   ],
   "id": "c27d7e79251ff382",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we will build Poisson model using PyMC.\n",
    "\n",
    "Here, there are some visulization of this model:\n",
    "\n",
    "\\begin{gather*}\n",
    "y_i \\sim Poisson(\\lambda_i)\\\\\n",
    "log(\\lambda_i) = E_i + \\gamma_i\\\\\n",
    "\\theta_{rg} \\sim Normal(5, 2)\\\\\n",
    "\\tau_{rg} \\sim HalfNormal(log(1.05))\\\\\n",
    "\\gamma_i \\sim Normal(\\theta_{r[i]g[i]}, \\tau_{r[i]g[i]})\\\\\n",
    "\\end{gather*}"
   ],
   "id": "3fa769f667f910ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pm.Model() as poisson_model:\n",
    "\n",
    "    # Hyperpriors pour chaque combinaison région-groupe\n",
    "    theta = pm.Normal('theta', mu=5, sigma=2,\n",
    "                     shape=(data['n_regions'], data['n_groups']))\n",
    "\n",
    "    tau = pm.HalfNormal('tau', sigma=np.log(1.05),\n",
    "                       shape=(data['n_regions'], data['n_groups']))\n",
    "\n",
    "    # Effets individuels pour chaque observation\n",
    "    gamma = pm.Normal('gamma',\n",
    "                     mu=theta[data['region_idx'], data['group_idx']],\n",
    "                     sigma=tau[data['region_idx'], data['group_idx']],\n",
    "                     shape=len(data['counts']))\n",
    "\n",
    "    # Paramètre du taux de Poisson\n",
    "    lambda_i = pm.math.exp(gamma)\n",
    "\n",
    "    # Vraisemblance\n",
    "    y_obs = pm.Poisson('y_obs', mu=lambda_i, observed=data['counts'])\n",
    "\n",
    "print(\"Modèle Poisson construit avec succès!\")\n",
    "print(poisson_model)\n"
   ],
   "id": "c1670877a2e78dfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ajustement du modèle Poisson\n",
    "print(\"Ajustement du modèle Poisson en cours...\")\n",
    "with poisson_model:\n",
    "    trace_poisson = pm.sample(draws=1000, chains=2,\n",
    "                             target_accept=0.8,\n",
    "                             return_inferencedata=True)\n",
    "\n",
    "print(\"Ajustement terminé!\")"
   ],
   "id": "6004a80a04b2e0ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "  # Diagnostics du modèle Poisson\n",
    "print(\"=== DIAGNOSTICS MODÈLE POISSON ===\")\n",
    "\n",
    "# Résumé\n",
    "summary_poisson = az.summary(trace_poisson)\n",
    "print(\"\\nRésumé des paramètres:\")\n",
    "print(summary_poisson.head(10))  # Afficher les 10 premiers paramètres\n",
    "\n",
    "# Vérification de convergence\n",
    "rhat_max = summary_poisson['r_hat'].max()\n",
    "print(f\"\\nR-hat maximum: {rhat_max:.3f}\")\n",
    "if rhat_max < 1.1:\n",
    "    print(\"✓ Convergence OK (R-hat < 1.1)\")\n",
    "else:\n",
    "    print(\"Problème de convergence possible\")\n",
    "\n",
    "# Graphiques de diagnostic\n",
    "az.plot_trace(trace_poisson, var_names=['theta', 'tau'], compact=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "84eaa3c31c375c2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we will build Horseshoe model using PyMC.\n",
    "\n",
    "Here, there are some visulization of this model:\n",
    "\n",
    "\\begin{gather*}\n",
    "y_i \\sim Poisson(\\lambda_i)\\\\\n",
    "log(\\lambda_i) = E_i + \\gamma_i\\\\\n",
    "\\theta_{rg} \\sim Normal(5, 2)\\\\\n",
    "\\tau_{rg} \\sim HalfNormal(log(1.05))\\\\\n",
    "\\kappa_i \\sim HalfNormal(1)\\\\\n",
    "\\gamma_i \\sim Normal(\\theta_{r[i]g[i]}, \\kappa_i\\times\\tau_{r[i]g[i]})\\\\\n",
    "\\end{gather*}"
   ],
   "id": "e495b20655321547"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pm.Model() as horseshoe_model:\n",
    "    # 1. Moyenne globale\n",
    "    mu_global = pm.Normal(\"mu_global\", mu=5, sigma=2)\n",
    "\n",
    "    # 2. Effets hiérarchiques par région\n",
    "    sigma_region = pm.HalfNormal(\"sigma_region\", sigma=1)\n",
    "    region_raw = pm.Normal(\"region_raw\", mu=0, sigma=1, shape=data['n_regions'])\n",
    "    region_effects = pm.Deterministic(\"region_effects\", region_raw * sigma_region)\n",
    "\n",
    "    # 3. Effets hiérarchiques par groupe\n",
    "    sigma_group = pm.HalfNormal(\"sigma_group\", sigma=1)\n",
    "    group_raw = pm.Normal(\"group_raw\", mu=0, sigma=1, shape=data['n_groups'])\n",
    "    group_effects = pm.Deterministic(\"group_effects\", group_raw * sigma_group)\n",
    "\n",
    "    # 4. Shrinkage Horseshoe pour chaque observation\n",
    "    kappa = pm.HalfNormal('kappa', sigma=1, shape=len(data['counts']))\n",
    "    gamma_raw = pm.Normal(\"gamma_raw\", mu=0, sigma=1, shape=len(data['counts']))\n",
    "\n",
    "    # 5. Combinaison de tous les effets\n",
    "    mu_i = (mu_global +\n",
    "            region_effects[data['region_idx']] +\n",
    "            group_effects[data['group_idx']])\n",
    "\n",
    "    gamma = pm.Deterministic(\"gamma\", mu_i + gamma_raw * kappa)\n",
    "\n",
    "    # 6. Paramètre du taux de Poisson\n",
    "    lambda_i = pm.math.exp(gamma)\n",
    "\n",
    "    # 7. Vraisemblance\n",
    "    y_obs = pm.Poisson('y_obs', mu=lambda_i, observed=data['counts'])\n",
    "\n",
    "print(\"✓ Modèle Horseshoe construit avec succès!\")"
   ],
   "id": "767f24a0198cef1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we will build Zero-inflated Poisson model using PyMC.\n",
    "\n",
    "Here, there are some visulization of this model:\n",
    "\n",
    "\\begin{gather*}\n",
    "y_i \\sim ZIPoisson(\\lambda_i,\\pi)\\\\\n",
    "log(\\lambda_i) = E_i + \\gamma_i\\\\\n",
    "\\pi \\sim Beta(1,5)\\\\\n",
    "\\theta_{rg} \\sim Normal(5, 2)\\\\\n",
    "\\tau_{rg} \\sim HalfNormal(log(1.05))\\\\\n",
    "\\gamma_i \\sim Normal(\\theta_{r[i]g[i]}, \\tau_{r[i]g[i]})\\\\\n",
    "\\end{gather*}"
   ],
   "id": "81fb1b1c6a715f89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pm.Model() as zero_inflatedpoisson_model:\n",
    "\n",
    "    # Paramètre de zero-inflation\n",
    "    pi = pm.Beta('pi', alpha=1, beta=5)\n",
    "\n",
    "    # Hyperpriors pour chaque combinaison région-groupe\n",
    "    theta = pm.Normal('theta', mu=5, sigma=2,\n",
    "                     shape=(data['n_regions'], data['n_groups']))\n",
    "\n",
    "    tau = pm.HalfNormal('tau', sigma=np.log(1.05),\n",
    "                       shape=(data['n_regions'], data['n_groups']))\n",
    "\n",
    "    # Effets individuels\n",
    "    gamma = pm.Normal('gamma',\n",
    "                     mu=theta[data['region_idx'], data['group_idx']],\n",
    "                     sigma=tau[data['region_idx'], data['group_idx']],\n",
    "                     shape=len(data['counts']))\n",
    "\n",
    "    # Paramètre du taux de Poisson\n",
    "    lambda_i = pm.math.exp(gamma)\n",
    "\n",
    "    # Vraisemblance Zero-Inflated Poisson\n",
    "    y_obs = pm.ZeroInflatedPoisson('y_obs', mu=lambda_i, psi=pi,\n",
    "                                  observed=data['counts'])\n",
    "\n",
    "print(\"Modèle Zero-Inflated Poisson construit avec succès!\")"
   ],
   "id": "dc79d2b700228f4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ajustement des trois modèles\n",
    "models = {\n",
    "    'Poisson': poisson_model,\n",
    "    'Horseshoe': horseshoe_model,\n",
    "    'ZIP': zero_inflatedpoisson_model\n",
    "}\n",
    "\n",
    "traces = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== AJUSTEMENT MODÈLE {model_name.upper()} ===\")\n",
    "    try:\n",
    "        with model:\n",
    "            trace = pm.sample(draws=1000, chains=2,\n",
    "                             target_accept=0.8,\n",
    "                             return_inferencedata=True)\n",
    "        traces[model_name] = trace\n",
    "        print(f\"✓ Modèle {model_name} ajusté avec succès!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur modèle {model_name}: {e}\")\n",
    "\n",
    "print(f\"\\n{len(traces)} modèles ajustés avec succès!\")"
   ],
   "id": "697dc83af5375eed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comparaison des modèles\n",
    "if len(traces) > 1:\n",
    "    print(\"=== COMPARAISON DES MODÈLES ===\")\n",
    "\n",
    "    # Calcul WAIC pour chaque modèle\n",
    "    waic_results = {}\n",
    "    for name, trace in traces.items():\n",
    "        waic = az.waic(trace)\n",
    "        waic_results[name] = waic\n",
    "        print(f\"{name}: WAIC = {waic.waic:.1f} ± {waic.se:.1f}\")\n",
    "\n",
    "    # Comparaison formelle\n",
    "    comparison = az.compare(traces)\n",
    "    print(\"\\nComparaison détaillée:\")\n",
    "    print(comparison)\n",
    "\n",
    "    # Graphique de comparaison\n",
    "    az.plot_compare(comparison)\n",
    "    plt.title('Comparaison des modèles (WAIC)')\n",
    "    plt.show()"
   ],
   "id": "3082edb74c55661a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualisation des résultats du meilleur modèle\n",
    "best_model_name = comparison.index[0]  # Le modèle avec le meilleur WAIC\n",
    "best_trace = traces[best_model_name]\n",
    "\n",
    "print(f\"Visualisation du meilleur modèle: {best_model_name}\")\n",
    "\n",
    "# Graphique des effets par groupe et région\n",
    "posterior = best_trace.posterior\n",
    "\n",
    "# Moyennes postérieures de theta\n",
    "theta_mean = posterior['theta'].mean(dim=['chain', 'draw'])\n",
    "\n",
    "# Créer un DataFrame pour la visualisation\n",
    "results_df = []\n",
    "for r in range(data['n_regions']):\n",
    "    for g in range(data['n_groups']):\n",
    "        results_df.append({\n",
    "            'Region': data['region_names'][r],\n",
    "            'Group': data['group_names'][g],\n",
    "            'Theta': float(theta_mean[r, g])\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Graphique en barres\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=results_df, x='Region', y='Theta', hue='Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f'Effets estimés par région et groupe - Modèle {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap des différences entre groupes\n",
    "theta_diff = theta_mean[:, 1] - theta_mean[:, 0]  # C-SSRI - A-SSRI\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(data['region_names'])), theta_diff)\n",
    "plt.yticks(range(len(data['region_names'])), data['region_names'])\n",
    "plt.xlabel('Différence C-SSRI - A-SSRI')\n",
    "plt.title('Différences entre groupes par région')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d277a098402f455f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
